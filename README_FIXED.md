# Google Maps Scraper - Version CorrigÃ©e

## ğŸ”§ Modifications apportÃ©es

Cette version corrige les problÃ¨mes suivants :
- âœ… Support du mode headless ET non-headless avec Xvfb
- âœ… Meilleure dÃ©tection anti-bot (masquage WebDriver)
- âœ… Plusieurs sÃ©lecteurs CSS de secours pour `[role="feed"]`
- âœ… Gestion amÃ©liorÃ©e du formulaire de consentement
- âœ… Meilleure extraction des donnÃ©es
- âœ… Gestion d'erreurs robuste avec screenshots de debug
- âœ… Logging dÃ©taillÃ© pour le diagnostic

## ğŸ“¦ Installation

### 1. Cloner le projet original

```bash
git clone https://github.com/conor-is-my-name/google-maps-scraper.git
cd google-maps-scraper
```

### 2. Remplacer les fichiers par les versions corrigÃ©es

Remplace les fichiers suivants dans ton projet :

```bash
# Dockerfile
cp Dockerfile.fixed Dockerfile

# Scraper
cp scraper.py.fixed gmaps_scraper_server/scraper.py

# API
cp main_api.py.fixed gmaps_scraper_server/main_api.py

# Docker Compose
cp docker-compose.yml.fixed docker-compose.yml

# Requirements
cp requirements.txt.fixed requirements.txt
```

### 3. Structure du projet

Assure-toi d'avoir cette structure :

```
google-maps-scraper/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ gmaps_scraper_server/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main_api.py
    â””â”€â”€ scraper.py
```

### 4. CrÃ©er le fichier __init__.py si absent

```bash
touch gmaps_scraper_server/__init__.py
```

## ğŸš€ DÃ©ploiement

### Option 1 : Docker (RecommandÃ©)

```bash
# ArrÃªter les conteneurs existants
docker-compose down

# Construire et dÃ©marrer
docker-compose up --build -d

# VÃ©rifier les logs
docker-compose logs -f
```

### Option 2 : Local (pour dÃ©veloppement)

```bash
# CrÃ©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Installer les navigateurs Playwright
playwright install chromium
playwright install-deps chromium

# DÃ©marrer l'API
uvicorn gmaps_scraper_server.main_api:app --host 0.0.0.0 --port 8001 --reload
```

## ğŸ§ª Tests

### 1. Test de santÃ©

```bash
curl http://localhost:8001/health
```

RÃ©ponse attendue :
```json
{
  "status": "healthy",
  "service": "google-maps-scraper"
}
```

### 2. Test de scraping (GET)

```bash
# Avec headless=true (par dÃ©faut)
curl "http://localhost:8001/scrape-get?query=hotel%20in%20paris&max_places=5&lang=en&headless=true"

# Avec plus de rÃ©sultats
curl "http://localhost:8001/scrape-get?query=restaurant%20in%20london&max_places=20&lang=en&headless=true"
```

### 3. Test de scraping (POST)

```bash
curl -X POST "http://localhost:8001/scrape" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "hotel in paris",
    "max_places": 10,
    "lang": "fr",
    "headless": true
  }'
```

### 4. Test avec IP locale

```bash
# Remplace 192.168.1.195 par ton IP
curl "http://192.168.1.195:8001/scrape-get?query=cafe%20in%20berlin&max_places=10&lang=en&headless=true"
```

## ğŸ“Š Format de rÃ©ponse

```json
{
  "success": true,
  "query": "hotel in paris",
  "total_results": 10,
  "results": [
    {
      "name": "HÃ´tel Plaza AthÃ©nÃ©e",
      "rating": "4.5",
      "reviews_count": "1234",
      "category": "5-star hotel",
      "url": "https://www.google.com/maps/place/..."
    }
  ]
}
```

## ğŸ” Diagnostic et Debug

### VÃ©rifier les logs du conteneur

```bash
# Logs en temps rÃ©el
docker-compose logs -f

# Logs des 100 derniÃ¨res lignes
docker logs gmaps_scraper_api --tail 100

# Entrer dans le conteneur
docker exec -it gmaps_scraper_api bash
```

### Endpoint de debug

```bash
curl http://localhost:8001/debug
```

### Screenshots de debug

Si le scraping Ã©choue, un screenshot est automatiquement sauvegardÃ© dans `/tmp/gmaps_error.png`.

Pour rÃ©cupÃ©rer ce screenshot :

```bash
docker cp gmaps_scraper_api:/tmp/gmaps_error.png ./debug_screenshot.png
```

## ğŸ¯ Utilisation avec n8n

### Node HTTP Request (GET)

```
URL: http://gmaps_scraper_api_service:8001/scrape-get
MÃ©thode: GET
Query Parameters:
  - query: {{ $json.search_query }}
  - max_places: 20
  - lang: en
  - headless: true
```

### Node HTTP Request (POST)

```
URL: http://gmaps_scraper_api_service:8001/scrape
MÃ©thode: POST
Body Type: JSON
Body:
{
  "query": "{{ $json.search_query }}",
  "max_places": 20,
  "lang": "en",
  "headless": true
}
```

## ğŸ› RÃ©solution des problÃ¨mes courants

### ProblÃ¨me : "Feed element not found"

**Solutions** :
1. VÃ©rifier le screenshot de debug
2. Augmenter les dÃ©lais d'attente
3. Essayer avec une query plus simple

### ProblÃ¨me : Aucun rÃ©sultat retournÃ©

**Solutions** :
1. Tester avec une query plus simple : "restaurant"
2. Changer de langue : `lang=fr` au lieu de `lang=en`
3. Ajouter des dÃ©lais entre les requÃªtes

### ProblÃ¨me : Conteneur crashe

```bash
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

## âœ… Checklist de dÃ©ploiement

- [ ] Fichiers remplacÃ©s
- [ ] `__init__.py` crÃ©Ã© dans `gmaps_scraper_server/`
- [ ] Docker Compose arrÃªtÃ© : `docker-compose down`
- [ ] Build sans cache : `docker-compose build --no-cache`
- [ ] Conteneur dÃ©marrÃ© : `docker-compose up -d`
- [ ] Health check OK : `curl http://localhost:8001/health`
- [ ] Test scraping OK
- [ ] Logs sans erreur

Bon scraping ! ğŸš€
