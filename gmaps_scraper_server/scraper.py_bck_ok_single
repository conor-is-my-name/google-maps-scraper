import logging
import asyncio
import urllib.parse
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def scrape_google_maps(query: str, max_places: int = 10, lang: str = "en", headless: bool = True, extract_details: bool = False):
    """
    Scrape Google Maps avec extraction optimisée
    
    Args:
        query: Requête de recherche
        max_places: Nombre maximum de résultats
        lang: Code langue
        headless: Mode headless
        extract_details: Si True, extrait toutes les infos depuis le panneau détails (téléphone, horaires, etc.)
    """
    results = []
    
    async with async_playwright() as p:
        try:
            logger.info(f"Launching browser (headless={headless})...")
            browser = await p.chromium.launch(
                headless=headless,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-features=IsolateOrigins,site-per-process',
                    '--disable-web-security',
                    '--disable-site-isolation-trials',
                    '--disable-gpu',
                    '--disable-software-rasterizer',
                    '--disable-extensions',
                    '--single-process',
                ]
            )
            
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale=lang,
                timezone_id='Europe/Paris',
                geolocation={'latitude': 48.8566, 'longitude': 2.3522},
                permissions=['geolocation']
            )
            
            await context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });
                Object.defineProperty(navigator, 'languages', { get: () => ['en-US', 'en', 'fr'] });
                window.chrome = { runtime: {} };
            """)
            
            page = await context.new_page()
            
            search_url = f"https://www.google.com/maps/search/{query.replace(' ', '+')}?hl={lang}"
            logger.info(f"Navigating to: {search_url}")
            
            await page.goto(search_url, wait_until='domcontentloaded', timeout=30000)
            await asyncio.sleep(2)
            
            # Gérer consentement
            logger.info("Checking for consent form...")
            consent_selectors = [
                'button:has-text("Accept all")',
                'button:has-text("Tout accepter")',
                'button[aria-label*="Accept"]',
            ]
            
            for selector in consent_selectors:
                try:
                    consent_button = await page.wait_for_selector(selector, timeout=3000)
                    if consent_button:
                        await consent_button.click()
                        logger.info(f"Clicked consent button")
                        await asyncio.sleep(2)
                        break
                except PlaywrightTimeout:
                    continue
            
            # Attendre résultats
            logger.info("Waiting for results to load...")
            feed_element = None
            feed_selectors = ['div[role="feed"]', '[role="feed"]']
            
            for selector in feed_selectors:
                try:
                    feed_element = await page.wait_for_selector(selector, timeout=10000, state='visible')
                    if feed_element:
                        logger.info(f"Found feed element")
                        break
                except PlaywrightTimeout:
                    continue
            
            if not feed_element:
                await page.screenshot(path='/tmp/gmaps_error.png')
                raise Exception("Feed element not found.")
            
            # Scroll
            logger.info("Scrolling to load places...")
            places_loaded = 0
            scroll_attempts = 0
            max_scroll_attempts = 20
            
            while places_loaded < max_places and scroll_attempts < max_scroll_attempts:
                try:
                    current_places = await page.query_selector_all('a[href*="/maps/place/"]')
                    places_loaded = len(current_places)
                    logger.info(f"Loaded {places_loaded} places so far...")
                    
                    if places_loaded >= max_places:
                        break
                    
                    await feed_element.evaluate('element => element.scrollTop = element.scrollHeight')
                    await asyncio.sleep(1.5)
                    scroll_attempts += 1
                    
                except Exception as e:
                    logger.warning(f"Error during scrolling: {e}")
                    scroll_attempts += 1
                    await asyncio.sleep(1)
            
            # Extraire infos
            logger.info(f"Extracting data from {min(places_loaded, max_places)} places...")
            place_links = await page.query_selector_all('a[href*="/maps/place/"]')
            
            for i, link in enumerate(place_links[:max_places]):
                try:
                    # Extraire URL
                    href = await link.get_attribute('href')
                    
                    # Nom depuis URL (fallback)
                    name = "N/A"
                    if href and '/maps/place/' in href:
                        try:
                            name_part = href.split('/maps/place/')[1].split('/data=')[0]
                            name = urllib.parse.unquote_plus(name_part)
                        except:
                            pass
                    
                    place_data = {
                        'name': name,
                        'url': href,
                    }
                    
                    # MODE DÉTAILS OU mode rapide avec extraction depuis panneau
                    if extract_details or True:  # Toujours extraire depuis le panneau pour avoir rating/category
                        logger.info(f"Clicking on: {name}")
                        try:
                            # Cliquer sur le lieu
                            await link.click()
                            await asyncio.sleep(2.5)  # Attendre chargement panneau
                            
                            # RATING depuis le panneau
                            rating = "N/A"
                            try:
                                # Le rating est dans un span avec aria-label
                                rating_selectors = [
                                    'div[role="main"] span[role="img"][aria-label*="star"]',
                                    'div[role="main"] span[aria-label*="Star"]',
                                    'button[jsaction*="pane.rating"] span[role="img"]'
                                ]
                                for sel in rating_selectors:
                                    rating_elem = await page.query_selector(sel)
                                    if rating_elem:
                                        aria = await rating_elem.get_attribute('aria-label')
                                        if aria and 'star' in aria.lower():
                                            # Extraire le nombre (ex: "4.5 stars" → "4.5")
                                            rating = aria.split()[0]
                                            break
                            except Exception as e:
                                logger.debug(f"Rating extraction error: {e}")
                            
                            # REVIEWS COUNT depuis le panneau
                            reviews_count = "0"
                            try:
                                reviews_selectors = [
                                    'button[jsaction*="pane.rating"] span[aria-label*="review"]',
                                    'button[aria-label*="review"]'
                                ]
                                for sel in reviews_selectors:
                                    reviews_elem = await page.query_selector(sel)
                                    if reviews_elem:
                                        aria = await reviews_elem.get_attribute('aria-label')
                                        if aria and 'review' in aria.lower():
                                            # Extraire le nombre (ex: "123 reviews" → "123")
                                            parts = aria.split()
                                            if parts:
                                                reviews_count = ''.join(filter(str.isdigit, parts[0]))
                                            break
                            except Exception as e:
                                logger.debug(f"Reviews extraction error: {e}")
                            
                            # CATEGORY depuis le panneau
                            category = "N/A"
                            try:
                                # La catégorie est souvent un bouton ou lien
                                category_selectors = [
                                    'button[jsaction*="pane.rating.category"]',
                                    'div[role="main"] button[class*="DkEaL"]'
                                ]
                                for sel in category_selectors:
                                    cat_elem = await page.query_selector(sel)
                                    if cat_elem:
                                        cat_text = await cat_elem.inner_text()
                                        if cat_text and cat_text.strip():
                                            category = cat_text.strip()
                                            break
                            except Exception as e:
                                logger.debug(f"Category extraction error: {e}")
                            
                            place_data.update({
                                'rating': rating,
                                'reviews_count': reviews_count,
                                'category': category,
                            })
                            
                            # Extraire détails supplémentaires si demandé
                            if extract_details:
                                # Téléphone
                                phone = "N/A"
                                try:
                                    phone_selectors = [
                                        'button[data-item-id*="phone"]',
                                        'button[aria-label*="Phone"]',
                                        'button[data-tooltip*="Copy phone"]'
                                    ]
                                    for sel in phone_selectors:
                                        phone_elem = await page.query_selector(sel)
                                        if phone_elem:
                                            phone_aria = await phone_elem.get_attribute('aria-label')
                                            if phone_aria:
                                                phone = phone_aria.split(':')[-1].strip()
                                                break
                                except Exception as e:
                                    logger.debug(f"Phone extraction error: {e}")
                                
                                # Site web
                                website = "N/A"
                                try:
                                    website_elem = await page.query_selector('a[data-item-id="authority"]')
                                    if website_elem:
                                        website = await website_elem.get_attribute('href')
                                except Exception as e:
                                    logger.debug(f"Website extraction error: {e}")
                                
                                # Adresse
                                address = "N/A"
                                try:
                                    address_elem = await page.query_selector('button[data-item-id="address"]')
                                    if address_elem:
                                        address_aria = await address_elem.get_attribute('aria-label')
                                        if address_aria:
                                            address = address_aria.split(':')[-1].strip()
                                except Exception as e:
                                    logger.debug(f"Address extraction error: {e}")
                                
                                # Horaires - plusieurs variantes
                                hours = "N/A"
                                try:
                                    # Variante 1: Bouton avec data-item-id
                                    hours_selectors = [
                                        'button[data-item-id*="oh"]',
                                        'button[aria-label*="Hide open hours"]',
                                        'button[aria-label*="Show open hours"]',
                                        'div[aria-label*="Show open hours"]',
                                        'div[aria-label*="Hide open hours"]'
                                    ]
                                    for sel in hours_selectors:
                                        hours_elem = await page.query_selector(sel)
                                        if hours_elem:
                                            hours_aria = await hours_elem.get_attribute('aria-label')
                                            if hours_aria:
                                                hours = hours_aria
                                                break
                                    
                                    # Variante 2: Chercher texte "Open" ou "Closed"
                                    if hours == "N/A":
                                        status_texts = await page.query_selector_all('div[role="main"] span')
                                        for span in status_texts:
                                            text = await span.inner_text()
                                            if text and ('open' in text.lower() or 'closed' in text.lower() or 'pm' in text.lower() or 'am' in text.lower()):
                                                hours = text
                                                break
                                                
                                except Exception as e:
                                    logger.debug(f"Hours extraction error: {e}")
                                
                                place_data.update({
                                    'phone': phone,
                                    'website': website,
                                    'address': address,
                                    'hours': hours,
                                })
                            
                        except Exception as e:
                            logger.warning(f"Error extracting details: {e}")
                    
                    results.append(place_data)
                    logger.info(f"Extracted: {name} (rating: {place_data.get('rating', 'N/A')})")
                    
                except Exception as e:
                    logger.warning(f"Error extracting place {i}: {e}")
                    continue
            
            await browser.close()
            
        except Exception as e:
            logger.error(f"An error occurred during scraping: {e}")
            if 'browser' in locals():
                await browser.close()
            raise
    
    logger.info(f"Scraping finished. Found details for {len(results)} places.")
    return results


async def main():
    """Test function"""
    results = await scrape_google_maps("restaurant sannois", max_places=2, lang="en", extract_details=True)
    for place in results:
        print(f"\n{place['name']}")
        print(f"  Rating: {place.get('rating', 'N/A')} ({place.get('reviews_count', '0')} reviews)")
        print(f"  Category: {place.get('category', 'N/A')}")
        print(f"  Phone: {place.get('phone', 'N/A')}")
        print(f"  Website: {place.get('website', 'N/A')}")
        print(f"  Address: {place.get('address', 'N/A')}")
        print(f"  Hours: {place.get('hours', 'N/A')}")


if __name__ == "__main__":
    asyncio.run(main())
